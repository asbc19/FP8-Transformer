{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FP8 Emulation Toolkit - INTEL\n",
    "https://github.com/IntelLabs/FP8-Emulation-Toolkit\n",
    "\n",
    "- Create simple tutorial to verify that emulator is working.\n",
    "- Post-training quantization to FP8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.models import AlexNet_Weights\n",
    "\n",
    "# import the emulator\n",
    "from mpemu import mpt_emu\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "# Set CPU or GPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Running on {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a Pre-trained model\n",
    "- Use AlexNet.  \n",
    "https://learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the most up-to-date weigths\n",
    "alexnet_test = models.alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "\n",
    "# Set the evaluation mode for inference\n",
    "# set dropout and batch normalization layers to evaluation mode before running inference. \n",
    "# Failing to do this will yield inconsistent inference results.\n",
    "alexnet_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained Model's state_dict:\n",
      "\n",
      "features.0.weight \t torch.Size([64, 3, 11, 11])\n",
      "features.0.bias \t torch.Size([64])\n",
      "features.3.weight \t torch.Size([192, 64, 5, 5])\n",
      "features.3.bias \t torch.Size([192])\n",
      "features.6.weight \t torch.Size([384, 192, 3, 3])\n",
      "features.6.bias \t torch.Size([384])\n",
      "features.8.weight \t torch.Size([256, 384, 3, 3])\n",
      "features.8.bias \t torch.Size([256])\n",
      "features.10.weight \t torch.Size([256, 256, 3, 3])\n",
      "features.10.bias \t torch.Size([256])\n",
      "classifier.1.weight \t torch.Size([4096, 9216])\n",
      "classifier.1.bias \t torch.Size([4096])\n",
      "classifier.4.weight \t torch.Size([4096, 4096])\n",
      "classifier.4.bias \t torch.Size([4096])\n",
      "classifier.6.weight \t torch.Size([1000, 4096])\n",
      "classifier.6.bias \t torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "# Print the load model's state_dict\n",
    "print(\"Pre-trained Model's state_dict:\\n\")\n",
    "for param_tensor in alexnet_test.state_dict():\n",
    "    print(param_tensor, \"\\t\", alexnet_test.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample weight: features.0.weight\n",
      "Dimension: torch.Size([64, 3, 11, 11])\n",
      "Type: torch.float32\n",
      "tensor([[[[ 1.1864e-01,  9.4069e-02,  9.5435e-02,  ...,  5.5822e-02,\n",
      "            2.1575e-02,  4.9963e-02],\n",
      "          [ 7.4882e-02,  3.8940e-02,  5.2979e-02,  ...,  2.5709e-02,\n",
      "           -1.1299e-02,  4.1590e-03],\n",
      "          [ 7.5425e-02,  3.8779e-02,  5.4930e-02,  ...,  4.3596e-02,\n",
      "            1.0225e-02,  1.3251e-02],\n",
      "          ...,\n",
      "          [ 9.3155e-02,  1.0374e-01,  6.7547e-02,  ..., -2.0277e-01,\n",
      "           -1.2839e-01, -1.1220e-01],\n",
      "          [ 4.3544e-02,  6.4916e-02,  3.6164e-02,  ..., -2.0248e-01,\n",
      "           -1.1376e-01, -1.0719e-01],\n",
      "          [ 4.7369e-02,  6.2543e-02,  2.4758e-02,  ..., -1.1844e-01,\n",
      "           -9.5567e-02, -8.3890e-02]],\n",
      "\n",
      "         [[-7.2634e-02, -5.7996e-02, -8.0661e-02,  ..., -6.0304e-04,\n",
      "           -2.5309e-02,  2.5471e-02],\n",
      "          [-6.9042e-02, -6.7562e-02, -7.6367e-02,  ..., -3.9616e-03,\n",
      "           -3.0402e-02,  1.0477e-02],\n",
      "          [-9.9517e-02, -8.5592e-02, -1.0521e-01,  ..., -2.6587e-02,\n",
      "           -2.2777e-02,  6.6451e-03],\n",
      "          ...,\n",
      "          [-1.5121e-01, -8.8735e-02, -9.6737e-02,  ...,  3.0853e-01,\n",
      "            1.8096e-01,  8.4297e-02],\n",
      "          [-1.4309e-01, -7.5710e-02, -7.2215e-02,  ...,  2.0417e-01,\n",
      "            1.6447e-01,  9.5166e-02],\n",
      "          [-8.5925e-02, -4.0134e-02, -5.1491e-02,  ...,  1.6352e-01,\n",
      "            1.4822e-01,  1.0196e-01]],\n",
      "\n",
      "         [[-2.3596e-02, -2.1258e-03, -2.7761e-02,  ...,  3.9940e-02,\n",
      "           -7.1123e-03,  3.2207e-02],\n",
      "          [ 2.5705e-04,  2.2468e-02,  8.9070e-03,  ...,  1.8771e-02,\n",
      "           -1.4155e-02,  1.8275e-02],\n",
      "          [ 5.4084e-03,  2.9397e-02,  3.3051e-04,  ...,  1.2054e-02,\n",
      "           -2.5237e-03,  8.3515e-03],\n",
      "          ...,\n",
      "          [-6.2826e-02, -1.1655e-02, -6.2080e-02,  ...,  1.0332e-01,\n",
      "           -9.4987e-03, -7.9570e-02],\n",
      "          [-4.5691e-02,  3.3726e-03, -3.9632e-02,  ..., -2.6448e-02,\n",
      "           -3.3500e-02, -7.6398e-02],\n",
      "          [-1.8700e-02,  1.1365e-02, -3.9671e-02,  ..., -6.8563e-02,\n",
      "           -4.1289e-02, -5.5473e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9950e-03,  2.9262e-03,  4.8212e-02,  ...,  6.1402e-02,\n",
      "            2.6121e-02,  1.9558e-02],\n",
      "          [-1.2579e-02, -4.8879e-03,  1.8490e-02,  ...,  5.3881e-02,\n",
      "            1.6377e-02,  2.3768e-02],\n",
      "          [ 3.6561e-03, -7.7510e-04,  2.6360e-02,  ..., -2.5849e-02,\n",
      "           -6.1798e-02,  2.6103e-02],\n",
      "          ...,\n",
      "          [-1.0812e-02, -4.6008e-03,  1.5122e-02,  ...,  2.9561e-02,\n",
      "            5.3272e-03,  6.8561e-02],\n",
      "          [ 2.7364e-04, -1.4850e-02,  7.8180e-03,  ...,  2.7172e-02,\n",
      "           -1.8095e-02,  5.2485e-02],\n",
      "          [-5.2470e-02, -4.6578e-02, -1.0951e-02,  ...,  4.3038e-03,\n",
      "           -2.6379e-03,  1.4406e-02]],\n",
      "\n",
      "         [[ 2.3965e-02,  2.2740e-02,  5.7586e-03,  ...,  7.2087e-03,\n",
      "           -2.4652e-02,  4.4658e-02],\n",
      "          [ 2.6914e-02,  4.4892e-02, -1.0872e-03,  ...,  4.4243e-02,\n",
      "           -2.1168e-02,  6.4538e-02],\n",
      "          [ 1.2421e-02,  1.0247e-02, -4.1554e-02,  ..., -1.2134e-01,\n",
      "           -1.6294e-01,  2.6266e-02],\n",
      "          ...,\n",
      "          [ 3.5926e-02,  5.3235e-02,  1.1016e-02,  ...,  1.2710e-02,\n",
      "           -2.9737e-02,  8.5926e-02],\n",
      "          [ 1.5623e-02,  2.1743e-02, -8.2941e-03,  ..., -3.2744e-03,\n",
      "           -5.4099e-02,  5.7634e-02],\n",
      "          [ 7.5254e-02,  8.7784e-02,  5.5804e-02,  ...,  5.2849e-02,\n",
      "            1.0612e-02,  9.3531e-02]],\n",
      "\n",
      "         [[-3.6488e-02,  6.6332e-03, -3.9035e-02,  ..., -1.5678e-02,\n",
      "           -7.9994e-02, -8.8658e-04],\n",
      "          [-5.1740e-03,  5.7395e-02,  8.9841e-03,  ...,  7.4166e-02,\n",
      "           -3.1792e-03,  4.2777e-02],\n",
      "          [-7.9446e-02, -2.2924e-02, -7.3370e-02,  ..., -5.6738e-02,\n",
      "           -1.2923e-01,  1.8896e-02],\n",
      "          ...,\n",
      "          [-3.9394e-02,  3.0981e-02, -2.7901e-02,  ..., -1.6774e-02,\n",
      "           -1.0236e-01,  4.0128e-02],\n",
      "          [-6.0751e-02, -2.3034e-02, -7.6838e-02,  ..., -7.9069e-02,\n",
      "           -1.6195e-01, -1.3746e-02],\n",
      "          [ 7.9522e-03,  4.6969e-02, -1.2460e-02,  ..., -4.6956e-02,\n",
      "           -1.0082e-01,  1.9832e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1702e-02,  1.3825e-02,  9.0514e-03,  ..., -9.6401e-02,\n",
      "           -1.1277e-01, -2.1596e-01],\n",
      "          [-9.0091e-02, -1.3136e-02, -3.2812e-02,  ..., -7.5263e-02,\n",
      "           -1.4803e-01, -2.9966e-01],\n",
      "          [-1.3155e-01, -4.2686e-02, -4.7744e-02,  ...,  2.1429e-01,\n",
      "            3.2543e-02, -1.7151e-01],\n",
      "          ...,\n",
      "          [-1.0621e-01, -9.7966e-02, -2.5551e-01,  ...,  1.2277e-01,\n",
      "            1.9287e-01,  1.2671e-01],\n",
      "          [-8.0761e-02, -6.1498e-02, -2.2312e-01,  ...,  3.5376e-02,\n",
      "            1.0532e-01,  1.0669e-01],\n",
      "          [ 3.8186e-02,  4.9957e-02, -1.2802e-01,  ..., -3.2927e-02,\n",
      "            1.8685e-02,  4.7146e-02]],\n",
      "\n",
      "         [[ 3.9013e-02,  6.4311e-03, -3.1710e-03,  ..., -2.1245e-02,\n",
      "            4.0516e-02,  1.1092e-01],\n",
      "          [ 6.5689e-02,  2.2132e-02,  6.6539e-03,  ..., -3.9448e-02,\n",
      "            2.7749e-02,  1.1404e-01],\n",
      "          [ 7.7954e-02,  4.0220e-02,  1.4047e-02,  ..., -1.5417e-01,\n",
      "           -9.2291e-02,  3.4460e-02],\n",
      "          ...,\n",
      "          [ 1.2836e-01,  9.4449e-02,  1.4659e-01,  ..., -6.0067e-02,\n",
      "           -9.0891e-02, -6.1129e-02],\n",
      "          [ 1.2683e-01,  1.0044e-01,  1.3754e-01,  ..., -2.2507e-02,\n",
      "           -6.6664e-02, -1.9906e-02],\n",
      "          [ 8.0509e-02,  7.8203e-02,  9.8934e-02,  ...,  9.2865e-03,\n",
      "           -3.4635e-02, -1.2395e-02]],\n",
      "\n",
      "         [[ 1.1535e-02, -2.6993e-02,  1.4820e-02,  ...,  9.4833e-02,\n",
      "            1.2044e-01,  1.1027e-01],\n",
      "          [ 9.2629e-03, -2.6680e-02,  1.2218e-02,  ...,  8.7219e-02,\n",
      "            1.5435e-01,  1.8049e-01],\n",
      "          [ 6.9946e-02,  1.3250e-02,  4.8007e-02,  ..., -5.6851e-02,\n",
      "            3.2596e-02,  1.6812e-01],\n",
      "          ...,\n",
      "          [-1.2187e-02, -3.3265e-02,  1.1284e-01,  ..., -6.7740e-02,\n",
      "           -1.0240e-01, -7.6188e-02],\n",
      "          [-6.0069e-03, -2.8631e-02,  1.1643e-01,  ..., -6.7597e-03,\n",
      "           -4.3772e-02, -3.1101e-02],\n",
      "          [-1.3355e-01, -1.4825e-01, -1.0060e-03,  ...,  1.8809e-02,\n",
      "           -6.4637e-03, -2.7061e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 9.0948e-03,  1.4823e-02,  4.7374e-03,  ...,  1.5540e-02,\n",
      "           -5.8369e-04, -1.9922e-02],\n",
      "          [ 2.8962e-04,  2.1229e-02, -1.3210e-02,  ...,  2.4388e-03,\n",
      "           -5.8485e-03, -2.0373e-02],\n",
      "          [-1.1050e-02,  1.0094e-02, -2.9625e-02,  ..., -1.4471e-02,\n",
      "           -1.7187e-02, -3.0534e-02],\n",
      "          ...,\n",
      "          [ 1.0013e-01,  9.1407e-02,  1.3077e-01,  ...,  1.5798e-01,\n",
      "            9.0361e-02,  7.8365e-02],\n",
      "          [ 1.1610e-01,  8.1846e-02,  8.2892e-02,  ..., -6.0174e-02,\n",
      "           -6.9412e-02, -5.0151e-02],\n",
      "          [-1.0564e-01, -1.1848e-01, -1.7681e-01,  ..., -2.0837e-01,\n",
      "           -1.8036e-01, -1.6691e-01]],\n",
      "\n",
      "         [[-1.1495e-02,  2.4917e-03, -8.2400e-03,  ..., -7.5865e-03,\n",
      "           -1.7387e-02, -1.7026e-02],\n",
      "          [-2.7461e-03, -1.1415e-02, -6.0670e-03,  ..., -2.8248e-02,\n",
      "           -2.2555e-02, -2.2559e-02],\n",
      "          [-8.4246e-03, -2.2378e-03, -3.5825e-02,  ..., -1.8462e-02,\n",
      "           -1.9795e-02, -2.4990e-02],\n",
      "          ...,\n",
      "          [ 1.2956e-01,  9.8057e-02,  1.4888e-01,  ...,  1.5655e-01,\n",
      "            7.9547e-02,  9.6928e-02],\n",
      "          [ 1.6080e-01,  1.0522e-01,  1.0264e-01,  ..., -6.5226e-02,\n",
      "           -6.4314e-02, -3.9066e-02],\n",
      "          [-1.2880e-01, -1.4656e-01, -1.9475e-01,  ..., -2.4177e-01,\n",
      "           -2.0277e-01, -1.9324e-01]],\n",
      "\n",
      "         [[-5.4209e-03, -1.7648e-03,  4.3163e-03,  ...,  9.8182e-03,\n",
      "            5.2347e-03,  6.3336e-03],\n",
      "          [ 9.3478e-03,  1.5920e-03, -2.1660e-03,  ...,  7.1244e-03,\n",
      "            9.3521e-04, -5.7647e-03],\n",
      "          [-1.3668e-03,  3.8899e-03, -7.7412e-03,  ...,  3.0651e-03,\n",
      "            1.4989e-02, -8.1730e-03],\n",
      "          ...,\n",
      "          [ 4.3937e-02,  7.9544e-04,  6.0613e-02,  ...,  7.4787e-02,\n",
      "            4.3960e-02,  5.6071e-02],\n",
      "          [ 1.0077e-01,  7.5126e-02,  1.0962e-01,  ...,  4.9886e-03,\n",
      "            1.0789e-02,  1.3402e-02],\n",
      "          [-8.8773e-02, -7.2790e-02, -9.2907e-02,  ..., -6.6530e-02,\n",
      "           -3.8977e-02, -4.8370e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5712e-03,  4.6908e-02, -1.6075e-02,  ...,  7.7790e-03,\n",
      "           -1.9798e-02,  6.8000e-03],\n",
      "          [ 6.2769e-02,  4.5108e-02,  4.7187e-02,  ...,  6.0599e-02,\n",
      "            2.9275e-02,  5.5794e-02],\n",
      "          [ 3.6748e-03,  1.2952e-02,  1.8988e-05,  ..., -8.3492e-03,\n",
      "           -1.9689e-03,  8.0830e-03],\n",
      "          ...,\n",
      "          [-4.4365e-02, -5.8858e-02, -2.4772e-02,  ..., -2.8423e-02,\n",
      "           -3.0897e-02, -5.2936e-02],\n",
      "          [-9.7572e-03, -4.3227e-02,  9.0068e-03,  ..., -4.2596e-02,\n",
      "           -1.8114e-02, -2.8028e-02],\n",
      "          [-2.2007e-02, -3.3594e-02,  1.3479e-02,  ..., -4.1530e-02,\n",
      "           -1.7819e-02, -5.1977e-02]],\n",
      "\n",
      "         [[-9.0596e-02, -5.1485e-02, -1.6459e-01,  ..., -1.1970e-01,\n",
      "           -1.1150e-01, -4.3914e-02],\n",
      "          [ 1.3835e-02,  2.6007e-02, -1.9440e-02,  ...,  2.3757e-02,\n",
      "            6.3709e-03,  5.4287e-02],\n",
      "          [-9.3225e-02, -4.7454e-02, -1.1274e-01,  ..., -8.6459e-02,\n",
      "           -7.3958e-02, -6.6610e-02],\n",
      "          ...,\n",
      "          [ 2.7382e-02,  1.0310e-02,  4.3906e-02,  ...,  2.7094e-02,\n",
      "            4.4510e-02,  1.5977e-02],\n",
      "          [ 9.8431e-02,  6.1433e-02,  1.1413e-01,  ...,  9.6398e-02,\n",
      "            1.0725e-01,  9.5719e-02],\n",
      "          [-1.5100e-02, -1.1830e-02,  4.8571e-02,  ...,  2.9060e-02,\n",
      "            5.6323e-02, -2.1631e-03]],\n",
      "\n",
      "         [[-1.3693e-01, -7.9341e-02, -2.1245e-01,  ..., -1.3633e-01,\n",
      "           -1.5123e-01, -6.3938e-02],\n",
      "          [ 1.5745e-02,  5.1443e-02, -1.8209e-02,  ...,  4.9085e-02,\n",
      "            1.9585e-02,  7.8095e-02],\n",
      "          [-1.7127e-01, -8.8734e-02, -1.7467e-01,  ..., -1.4431e-01,\n",
      "           -1.3364e-01, -1.1878e-01],\n",
      "          ...,\n",
      "          [ 5.1982e-02,  1.5912e-02,  7.0009e-02,  ...,  4.4396e-02,\n",
      "            6.5429e-02,  2.6919e-02],\n",
      "          [ 1.3144e-01,  9.1333e-02,  1.6228e-01,  ...,  1.4230e-01,\n",
      "            1.5500e-01,  1.3808e-01],\n",
      "          [ 3.7818e-03, -2.0365e-02,  7.8663e-02,  ...,  8.6037e-02,\n",
      "            1.2596e-01,  3.8774e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.5081e-02,  5.6581e-02,  1.4016e-01,  ..., -1.4826e-02,\n",
      "            1.0425e-02, -3.7919e-03],\n",
      "          [ 6.0412e-02,  1.2531e-01, -1.2366e-01,  ...,  7.8628e-02,\n",
      "           -1.0564e-02, -2.2228e-02],\n",
      "          [ 1.0304e-01, -1.3654e-01, -1.9601e-01,  ..., -5.1919e-02,\n",
      "           -8.3287e-02,  3.9678e-02],\n",
      "          ...,\n",
      "          [-1.8598e-01,  1.5479e-02,  3.3912e-01,  ...,  2.7509e-01,\n",
      "            1.0493e-01, -1.6863e-01],\n",
      "          [ 6.8278e-02,  1.3989e-01,  1.1350e-02,  ..., -7.8728e-02,\n",
      "           -2.5001e-01, -8.0072e-02],\n",
      "          [ 5.1736e-03, -6.8372e-02, -9.1940e-02,  ..., -1.0727e-01,\n",
      "            8.7973e-02,  1.0139e-01]],\n",
      "\n",
      "         [[-9.8760e-02,  6.2635e-02,  1.1495e-01,  ..., -1.3191e-02,\n",
      "            1.9574e-02, -1.0864e-03],\n",
      "          [ 8.3206e-02,  1.0300e-01, -1.5419e-01,  ...,  1.0864e-01,\n",
      "            1.2592e-02, -2.0278e-02],\n",
      "          [ 1.1248e-01, -1.6928e-01, -1.8876e-01,  ..., -6.3491e-02,\n",
      "           -9.3101e-02,  4.9006e-02],\n",
      "          ...,\n",
      "          [-1.8867e-01,  6.7374e-02,  4.8128e-01,  ...,  3.1371e-01,\n",
      "            1.6068e-01, -1.3449e-01],\n",
      "          [ 1.1207e-01,  2.0871e-01,  4.6815e-02,  ..., -7.0456e-03,\n",
      "           -2.2978e-01, -6.9528e-02],\n",
      "          [ 1.7255e-02, -9.1683e-02, -1.5943e-01,  ..., -8.0373e-02,\n",
      "            8.0035e-02,  1.1819e-01]],\n",
      "\n",
      "         [[-1.0580e-01,  5.4381e-02,  1.3048e-01,  ..., -3.9546e-02,\n",
      "            1.1924e-02, -2.7886e-03],\n",
      "          [ 5.7859e-02,  1.0646e-01, -1.3468e-01,  ...,  1.0645e-01,\n",
      "            1.8412e-02, -1.3245e-03],\n",
      "          [ 1.0398e-01, -1.0849e-01, -1.6758e-01,  ..., -4.2554e-02,\n",
      "           -8.5875e-02,  5.2581e-02],\n",
      "          ...,\n",
      "          [-1.8241e-01,  5.4228e-02,  3.9395e-01,  ...,  2.4432e-01,\n",
      "            1.0216e-01, -1.2876e-01],\n",
      "          [ 8.5720e-02,  1.8378e-01,  5.0316e-02,  ..., -4.7009e-02,\n",
      "           -2.1584e-01, -4.2482e-02],\n",
      "          [ 3.9612e-02, -7.6353e-02, -1.3502e-01,  ..., -4.8630e-02,\n",
      "            1.0063e-01,  9.0307e-02]]]])\n"
     ]
    }
   ],
   "source": [
    "# Print one weight sample\n",
    "sample = \"features.0.weight\"\n",
    "print(f'Sample weight: {sample}')\n",
    "print(f'Dimension: {alexnet_test.state_dict()[sample].shape}')\n",
    "print(f'Type: {alexnet_test.state_dict()[sample].dtype}')\n",
    "print(alexnet_test.state_dict()[sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quantize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a deep copy of the model since the function overwrite it\n",
    "alexnet_to_q = copy.deepcopy(alexnet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers exempt from e4m3 conversion\n",
    "list_exempt_layers = [\"classifier.6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e4m3 : quantizing model weights..\n"
     ]
    }
   ],
   "source": [
    "model_fp8, emulator = mpt_emu.quantize_model (model=alexnet_to_q, dtype=\"E4M3\",\n",
    "                               list_exempt_layers=list_exempt_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model's state_dict:\n",
      "\n",
      "features.0.weight \t torch.Size([64, 3, 11, 11])\n",
      "features.0.bias \t torch.Size([64])\n",
      "features.3.weight \t torch.Size([192, 64, 5, 5])\n",
      "features.3.bias \t torch.Size([192])\n",
      "features.6.weight \t torch.Size([384, 192, 3, 3])\n",
      "features.6.bias \t torch.Size([384])\n",
      "features.8.weight \t torch.Size([256, 384, 3, 3])\n",
      "features.8.bias \t torch.Size([256])\n",
      "features.10.weight \t torch.Size([256, 256, 3, 3])\n",
      "features.10.bias \t torch.Size([256])\n",
      "classifier.1.weight \t torch.Size([4096, 9216])\n",
      "classifier.1.bias \t torch.Size([4096])\n",
      "classifier.4.weight \t torch.Size([4096, 4096])\n",
      "classifier.4.bias \t torch.Size([4096])\n",
      "classifier.6.weight \t torch.Size([1000, 4096])\n",
      "classifier.6.bias \t torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "# Print the quantized model's state_dict\n",
    "print(\"Quantized Model's state_dict:\\n\")\n",
    "for param_tensor in model_fp8.state_dict():\n",
    "    print(param_tensor, \"\\t\", model_fp8.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quantized Layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample weight (Original): features.8.weight\n",
      "Dimension: torch.Size([256, 384, 3, 3])\n",
      "Type: torch.float32\n",
      "tensor([[[[-0.0020, -0.0081, -0.0114],\n",
      "          [-0.0193,  0.0007,  0.0114],\n",
      "          [-0.0541, -0.0012, -0.0244]],\n",
      "\n",
      "         [[ 0.0350,  0.0133,  0.0260],\n",
      "          [-0.0282, -0.0062, -0.0269],\n",
      "          [ 0.0035,  0.0181,  0.0147]],\n",
      "\n",
      "         [[-0.0572, -0.0474,  0.0019],\n",
      "          [-0.0402, -0.0462, -0.0257],\n",
      "          [-0.0515, -0.0490,  0.0254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0184, -0.0234,  0.0097],\n",
      "          [-0.0443, -0.0076, -0.0178],\n",
      "          [-0.0518, -0.0351, -0.0455]],\n",
      "\n",
      "         [[-0.0037, -0.0011, -0.0447],\n",
      "          [-0.0524, -0.0318, -0.0524],\n",
      "          [-0.0031, -0.0111, -0.0443]],\n",
      "\n",
      "         [[-0.0199, -0.0015,  0.0159],\n",
      "          [ 0.0051, -0.0149, -0.0237],\n",
      "          [ 0.0259,  0.0332,  0.0081]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0210,  0.0214,  0.0528],\n",
      "          [-0.0056,  0.0240,  0.0338],\n",
      "          [-0.0091,  0.0343,  0.0236]],\n",
      "\n",
      "         [[-0.0239, -0.0183, -0.0083],\n",
      "          [ 0.0316,  0.0136,  0.0453],\n",
      "          [-0.0357,  0.0247,  0.0101]],\n",
      "\n",
      "         [[ 0.0013,  0.0397,  0.0254],\n",
      "          [ 0.0308,  0.0113, -0.0031],\n",
      "          [-0.0280,  0.0023, -0.0184]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0195, -0.0042, -0.0179],\n",
      "          [ 0.0192,  0.0265,  0.0026],\n",
      "          [ 0.0137, -0.0102,  0.0086]],\n",
      "\n",
      "         [[ 0.0275,  0.0256,  0.0252],\n",
      "          [-0.0102, -0.0263, -0.0122],\n",
      "          [-0.0340,  0.0067,  0.0385]],\n",
      "\n",
      "         [[-0.0022,  0.0217,  0.0112],\n",
      "          [ 0.0122, -0.0210,  0.0075],\n",
      "          [-0.0028, -0.0052, -0.0128]]],\n",
      "\n",
      "\n",
      "        [[[-0.0329, -0.0248, -0.0185],\n",
      "          [-0.0054,  0.0061,  0.0126],\n",
      "          [ 0.0478,  0.0188,  0.0413]],\n",
      "\n",
      "         [[-0.0074, -0.0016,  0.0026],\n",
      "          [ 0.0047, -0.0048,  0.0078],\n",
      "          [-0.0068,  0.0028,  0.0143]],\n",
      "\n",
      "         [[ 0.0005, -0.0228, -0.0027],\n",
      "          [-0.0152, -0.0249,  0.0235],\n",
      "          [ 0.0053, -0.0205,  0.0647]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0352, -0.0149,  0.0171],\n",
      "          [-0.0023, -0.0084, -0.0010],\n",
      "          [-0.0209,  0.0037, -0.0223]],\n",
      "\n",
      "         [[-0.0042, -0.0047, -0.0100],\n",
      "          [-0.0069, -0.0281, -0.0387],\n",
      "          [ 0.0048,  0.0333,  0.0114]],\n",
      "\n",
      "         [[-0.0421,  0.0002, -0.0347],\n",
      "          [-0.0001,  0.0014, -0.0092],\n",
      "          [ 0.0719,  0.0502,  0.0573]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0410,  0.0385,  0.0163],\n",
      "          [ 0.0073, -0.0176, -0.0462],\n",
      "          [-0.0201, -0.0263, -0.0473]],\n",
      "\n",
      "         [[ 0.0129,  0.0227,  0.0252],\n",
      "          [ 0.0145,  0.0254,  0.0300],\n",
      "          [-0.0025,  0.0151,  0.0112]],\n",
      "\n",
      "         [[-0.0199, -0.0113, -0.0104],\n",
      "          [ 0.0127,  0.0129,  0.0073],\n",
      "          [ 0.0161,  0.0055, -0.0063]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0302,  0.0051, -0.0012],\n",
      "          [ 0.0208,  0.0003, -0.0187],\n",
      "          [-0.0144, -0.0357, -0.0175]],\n",
      "\n",
      "         [[ 0.0599,  0.0085,  0.0075],\n",
      "          [ 0.0610,  0.0170, -0.0337],\n",
      "          [ 0.0119,  0.0251, -0.0149]],\n",
      "\n",
      "         [[-0.0455, -0.0504, -0.0410],\n",
      "          [-0.0200, -0.0281, -0.0193],\n",
      "          [-0.0178, -0.0225, -0.0468]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0077, -0.0249,  0.0156],\n",
      "          [-0.0249,  0.0043,  0.0494],\n",
      "          [ 0.0045,  0.0455,  0.0455]],\n",
      "\n",
      "         [[ 0.0105,  0.0247, -0.0057],\n",
      "          [ 0.0461,  0.0305,  0.0349],\n",
      "          [-0.0354,  0.0422, -0.0025]],\n",
      "\n",
      "         [[ 0.0247,  0.0364,  0.0006],\n",
      "          [-0.0022, -0.0204, -0.0010],\n",
      "          [-0.0189, -0.0207, -0.0254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0123, -0.0342, -0.0004],\n",
      "          [-0.0067, -0.0245, -0.0082],\n",
      "          [-0.0122,  0.0133,  0.0139]],\n",
      "\n",
      "         [[ 0.0098,  0.0259,  0.0180],\n",
      "          [ 0.0376,  0.0472,  0.0034],\n",
      "          [ 0.0239, -0.0019, -0.0128]],\n",
      "\n",
      "         [[ 0.0087,  0.0292, -0.0075],\n",
      "          [ 0.0031, -0.0118, -0.0158],\n",
      "          [-0.0128, -0.0524,  0.0036]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0005,  0.0481,  0.0279],\n",
      "          [ 0.0006, -0.0294, -0.0090],\n",
      "          [ 0.0095,  0.0028,  0.0157]],\n",
      "\n",
      "         [[ 0.0166,  0.0328,  0.0182],\n",
      "          [-0.0055,  0.0275,  0.0119],\n",
      "          [-0.0541, -0.0190, -0.0386]],\n",
      "\n",
      "         [[-0.0386, -0.0353,  0.0143],\n",
      "          [-0.0577, -0.0483,  0.0289],\n",
      "          [-0.0361,  0.0032,  0.0618]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0133,  0.0259,  0.0499],\n",
      "          [ 0.0033, -0.0500,  0.0009],\n",
      "          [ 0.0153,  0.0184,  0.0001]],\n",
      "\n",
      "         [[-0.0324, -0.0163,  0.0237],\n",
      "          [-0.0012, -0.0137,  0.0037],\n",
      "          [-0.0236,  0.0041,  0.0363]],\n",
      "\n",
      "         [[-0.0293, -0.0176, -0.0268],\n",
      "          [-0.0341,  0.0460, -0.0113],\n",
      "          [ 0.0003,  0.0701,  0.0068]]]])\n"
     ]
    }
   ],
   "source": [
    "# Print one weight sample\n",
    "sample = \"features.8.weight\"\n",
    "print(f'Sample weight (Original): {sample}')\n",
    "print(f'Dimension: {alexnet_test.state_dict()[sample].shape}')\n",
    "print(f'Type: {alexnet_test.state_dict()[sample].dtype}')\n",
    "print(alexnet_test.state_dict()[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample weight (Quantized): features.8.weight\n",
      "Dimension: torch.Size([256, 384, 3, 3])\n",
      "Type: torch.float32\n",
      "tensor([[[[-1.9568e-03, -8.4293e-03, -1.0838e-02],\n",
      "          [-1.9267e-02,  6.7735e-04,  1.0838e-02],\n",
      "          [-5.2984e-02, -1.1289e-03, -2.4084e-02]],\n",
      "\n",
      "         [[ 3.6125e-02,  1.3246e-02,  2.6492e-02],\n",
      "          [-2.8900e-02, -6.0209e-03, -2.6492e-02],\n",
      "          [ 3.3115e-03,  1.8063e-02,  1.4450e-02]],\n",
      "\n",
      "         [[-5.7801e-02, -4.8167e-02,  1.8063e-03],\n",
      "          [-3.8534e-02, -4.8167e-02, -2.6492e-02],\n",
      "          [-5.2984e-02, -4.8167e-02,  2.6492e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8063e-02, -2.4084e-02,  9.6335e-03],\n",
      "          [-4.3351e-02, -7.8272e-03, -1.8063e-02],\n",
      "          [-5.2984e-02, -3.6125e-02, -4.3351e-02]],\n",
      "\n",
      "         [[-3.6125e-03, -1.1289e-03, -4.3351e-02],\n",
      "          [-5.2984e-02, -3.1309e-02, -5.2984e-02],\n",
      "          [-3.0105e-03, -1.0838e-02, -4.3351e-02]],\n",
      "\n",
      "         [[-1.9267e-02, -1.5052e-03,  1.5654e-02],\n",
      "          [ 4.8167e-03, -1.4450e-02, -2.4084e-02],\n",
      "          [ 2.6492e-02,  3.3717e-02,  7.8272e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1526e-02,  2.1526e-02,  5.0880e-02],\n",
      "          [-5.8708e-03,  2.3483e-02,  3.5225e-02],\n",
      "          [-8.8062e-03,  3.5225e-02,  2.3483e-02]],\n",
      "\n",
      "         [[-2.3483e-02, -1.7612e-02, -7.8278e-03],\n",
      "          [ 3.1311e-02,  1.3699e-02,  4.6967e-02],\n",
      "          [-3.5225e-02,  2.5440e-02,  9.7847e-03]],\n",
      "\n",
      "         [[ 1.3454e-03,  3.9139e-02,  2.5440e-02],\n",
      "          [ 3.1311e-02,  1.1742e-02, -3.1800e-03],\n",
      "          [-2.7397e-02,  2.2016e-03, -1.7612e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9569e-02, -4.4031e-03, -1.7612e-02],\n",
      "          [ 1.9569e-02,  2.7397e-02,  2.4462e-03],\n",
      "          [ 1.3699e-02, -9.7847e-03,  8.8062e-03]],\n",
      "\n",
      "         [[ 2.7397e-02,  2.5440e-02,  2.5440e-02],\n",
      "          [-9.7847e-03, -2.5440e-02, -1.1742e-02],\n",
      "          [-3.5225e-02,  6.8493e-03,  3.9139e-02]],\n",
      "\n",
      "         [[-2.2016e-03,  2.1526e-02,  1.0763e-02],\n",
      "          [ 1.1742e-02, -2.1526e-02,  7.3385e-03],\n",
      "          [-2.9354e-03, -5.3816e-03, -1.2720e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1754e-02, -2.4950e-02, -1.8145e-02],\n",
      "          [-5.6704e-03,  6.2375e-03,  1.2475e-02],\n",
      "          [ 4.9900e-02,  1.8145e-02,  4.0827e-02]],\n",
      "\n",
      "         [[-7.3716e-03, -1.5594e-03,  2.5517e-03],\n",
      "          [ 4.5363e-03, -5.1034e-03,  7.9386e-03],\n",
      "          [-6.8045e-03,  2.8352e-03,  1.4743e-02]],\n",
      "\n",
      "         [[ 4.6072e-04, -2.2682e-02, -2.8352e-03],\n",
      "          [-1.4743e-02, -2.4950e-02,  2.2682e-02],\n",
      "          [ 5.1034e-03, -2.0414e-02,  6.3509e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.6291e-02, -1.4743e-02,  1.7011e-02],\n",
      "          [-2.2682e-03, -8.5057e-03, -9.9233e-04],\n",
      "          [-2.0414e-02,  3.6858e-03, -2.2682e-02]],\n",
      "\n",
      "         [[-4.2528e-03, -4.5363e-03, -1.0207e-02],\n",
      "          [-6.8045e-03, -2.7218e-02, -4.0827e-02],\n",
      "          [ 4.5363e-03,  3.4023e-02,  1.1341e-02]],\n",
      "\n",
      "         [[-4.0827e-02,  1.9492e-04, -3.4023e-02],\n",
      "          [-1.1518e-04,  1.4176e-03, -9.0727e-03],\n",
      "          [ 7.2582e-02,  4.9900e-02,  5.8973e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.0885e-02,  3.7168e-02,  1.6726e-02],\n",
      "          [ 7.4336e-03, -1.6726e-02, -4.4602e-02],\n",
      "          [-2.0442e-02, -2.6018e-02, -4.8318e-02]],\n",
      "\n",
      "         [[ 1.3009e-02,  2.2301e-02,  2.6018e-02],\n",
      "          [ 1.4867e-02,  2.6018e-02,  2.9734e-02],\n",
      "          [-2.5553e-03,  1.4867e-02,  1.1150e-02]],\n",
      "\n",
      "         [[-2.0442e-02, -1.1150e-02, -1.0221e-02],\n",
      "          [ 1.3009e-02,  1.3009e-02,  7.4336e-03],\n",
      "          [ 1.6726e-02,  5.5752e-03, -6.5044e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9734e-02,  5.1106e-03, -1.1615e-03],\n",
      "          [ 2.0442e-02,  3.1941e-04, -1.8584e-02],\n",
      "          [-1.4867e-02, -3.7168e-02, -1.6726e-02]],\n",
      "\n",
      "         [[ 5.9469e-02,  8.3628e-03,  7.4336e-03],\n",
      "          [ 5.9469e-02,  1.6726e-02, -3.3451e-02],\n",
      "          [ 1.2080e-02,  2.4159e-02, -1.4867e-02]],\n",
      "\n",
      "         [[-4.4602e-02, -5.2035e-02, -4.0885e-02],\n",
      "          [-2.0442e-02, -2.7876e-02, -1.8584e-02],\n",
      "          [-1.8584e-02, -2.2301e-02, -4.8318e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7058e-03, -2.4218e-02,  1.5412e-02],\n",
      "          [-2.4218e-02,  4.4033e-03,  4.8436e-02],\n",
      "          [ 4.4033e-03,  4.4033e-02,  4.4033e-02]],\n",
      "\n",
      "         [[ 1.1008e-02,  2.4218e-02, -5.5041e-03],\n",
      "          [ 4.4033e-02,  3.0823e-02,  3.5226e-02],\n",
      "          [-3.5226e-02,  4.4033e-02, -2.4769e-03]],\n",
      "\n",
      "         [[ 2.4218e-02,  3.5226e-02,  6.1922e-04],\n",
      "          [-2.2017e-03, -1.9815e-02, -1.0320e-03],\n",
      "          [-1.9815e-02, -1.9815e-02, -2.6420e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2109e-02, -3.5226e-02, -3.4401e-04],\n",
      "          [-6.6050e-03, -2.4218e-02, -8.2562e-03],\n",
      "          [-1.2109e-02,  1.3210e-02,  1.4311e-02]],\n",
      "\n",
      "         [[ 9.9074e-03,  2.6420e-02,  1.7613e-02],\n",
      "          [ 3.9630e-02,  4.8436e-02,  3.3025e-03],\n",
      "          [ 2.4218e-02, -1.9264e-03, -1.3210e-02]],\n",
      "\n",
      "         [[ 8.8066e-03,  2.8621e-02, -7.7058e-03],\n",
      "          [ 3.0273e-03, -1.2109e-02, -1.5412e-02],\n",
      "          [-1.3210e-02, -5.2840e-02,  3.5777e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8876e-04,  4.6921e-02,  2.8153e-02],\n",
      "          [ 5.8652e-04, -2.8153e-02, -8.6022e-03],\n",
      "          [ 9.3842e-03,  2.7371e-03,  1.5640e-02]],\n",
      "\n",
      "         [[ 1.7204e-02,  3.1281e-02,  1.8768e-02],\n",
      "          [-5.4741e-03,  2.8153e-02,  1.1730e-02],\n",
      "          [-5.6305e-02, -1.8768e-02, -3.7537e-02]],\n",
      "\n",
      "         [[-3.7537e-02, -3.4409e-02,  1.4076e-02],\n",
      "          [-5.6305e-02, -4.6921e-02,  2.8153e-02],\n",
      "          [-3.7537e-02,  3.1281e-03,  6.2562e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4076e-02,  2.5025e-02,  5.0049e-02],\n",
      "          [ 3.5191e-03, -5.0049e-02,  8.7977e-04],\n",
      "          [ 1.5640e-02,  1.8768e-02,  9.7753e-05]],\n",
      "\n",
      "         [[-3.1281e-02, -1.5640e-02,  2.3461e-02],\n",
      "          [-1.1730e-03, -1.4076e-02,  3.5191e-03],\n",
      "          [-2.3461e-02,  3.9101e-03,  3.7537e-02]],\n",
      "\n",
      "         [[-2.8153e-02, -1.7204e-02, -2.8153e-02],\n",
      "          [-3.4409e-02,  4.6921e-02, -1.0948e-02],\n",
      "          [ 2.6882e-04,  6.8818e-02,  7.0382e-03]]]])\n"
     ]
    }
   ],
   "source": [
    "# Print weight samples\n",
    "sample = \"features.8.weight\"\n",
    "print(f'Sample weight (Quantized): {sample}')\n",
    "print(f'Dimension: {model_fp8.state_dict()[sample].shape}')\n",
    "print(f'Type: {model_fp8.state_dict()[sample].dtype}')\n",
    "print(model_fp8.state_dict()[sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ommited Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample weight (Original): classifier.6.weight\n",
      "Dimension: torch.Size([1000, 4096])\n",
      "Type: torch.float32\n",
      "tensor([[ 0.0327, -0.0062, -0.0040,  ...,  0.0160,  0.0456, -0.0158],\n",
      "        [-0.0281,  0.0393, -0.0035,  ..., -0.0250,  0.0265, -0.0159],\n",
      "        [-0.0019, -0.0004, -0.0081,  ..., -0.0093,  0.0203, -0.0136],\n",
      "        ...,\n",
      "        [-0.0249, -0.0350,  0.0131,  ..., -0.0082,  0.0454, -0.0043],\n",
      "        [ 0.0252, -0.0026, -0.0109,  ..., -0.0091, -0.0615, -0.0009],\n",
      "        [-0.0039,  0.0090, -0.0018,  ...,  0.0229,  0.0042,  0.0185]])\n"
     ]
    }
   ],
   "source": [
    "# Print one weight sample that was ommited\n",
    "sample = \"classifier.6.weight\"\n",
    "print(f'Sample weight (Original): {sample}')\n",
    "print(f'Dimension: {alexnet_test.state_dict()[sample].shape}')\n",
    "print(f'Type: {alexnet_test.state_dict()[sample].dtype}')\n",
    "print(alexnet_test.state_dict()[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample weight (Quantized Model): classifier.6.weight\n",
      "Dimension: torch.Size([1000, 4096])\n",
      "Type: torch.float32\n",
      "tensor([[ 0.0327, -0.0062, -0.0040,  ...,  0.0160,  0.0456, -0.0158],\n",
      "        [-0.0281,  0.0393, -0.0035,  ..., -0.0250,  0.0265, -0.0159],\n",
      "        [-0.0019, -0.0004, -0.0081,  ..., -0.0093,  0.0203, -0.0136],\n",
      "        ...,\n",
      "        [-0.0249, -0.0350,  0.0131,  ..., -0.0082,  0.0454, -0.0043],\n",
      "        [ 0.0252, -0.0026, -0.0109,  ..., -0.0091, -0.0615, -0.0009],\n",
      "        [-0.0039,  0.0090, -0.0018,  ...,  0.0229,  0.0042,  0.0185]])\n"
     ]
    }
   ],
   "source": [
    "# Print weight samples that was ommited\n",
    "sample = \"classifier.6.weight\"\n",
    "print(f'Sample weight (Quantized Model): {sample}')\n",
    "print(f'Dimension: {model_fp8.state_dict()[sample].shape}')\n",
    "print(f'Type: {model_fp8.state_dict()[sample].dtype}')\n",
    "print(model_fp8.state_dict()[sample])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
